# Towards a future of amplified developers

## Introduction

We believe in a future where developers are amplified, not automated. This is why we, [Continue](https://continue.dev), are on a mission to make building software feel like making music.

In the era of [Large Language Models (LLMs)](https://www.youtube.com/watch?v=zjkBMFhNj_g), software development is becoming increasingly automated by “AI copilots”. Many folks are already forecasting that AI will replace developers in as little as a few years, while investors declare the arrival of “superhuman AI software engineers”.

Our motivation is to 1) spark a counter narrative that empowers developers instead of scaring or annoying them and 2) raise awareness of some systemic issues that we’ve seen in how engineering organizations are adopting, using, and evolving AI software development systems.

Our hope is that, over time, we can find a shared vocabulary for discussing these problems. For now, we describe the [current state of the world](#where-we-are-today), [where we are heading](#where-we-are-heading), and [how you can advocate for an AI software development system that amplifies devs at your organization](#how-to-be-prepared).

## Where we are today

What we call “AI copilots” are much more than a single LLM. As the Berkeley Artificial Intelligence Research Lab points out, [“state-of-the-art AI results are increasingly obtained by compound systems with multiple components, not just monolithic models”](https://bair.berkeley.edu/blog/2024/02/18/compound-ai-systems/).

As more of software development is automated, we are seeing more human engineering time go into monitoring, maintaining, and improving the different components that make up AI software development systems. That said, most copilots to date have been black box, SaaS solutions with roughly the same components, which you often have little to no ability to understand or improve.

- ["Tab" model](./where-we-are-today/tab.md)
- ["Chat" model](./where-we-are-today/chat.md)
- [Local context engine](./where-we-are-today/local.md)
- [Server context engine](./where-we-are-today/server.md)
- [Filtering](./where-we-are-today/filtering.md)

## Where we are heading

Among the changes on the horizon are two new components (async engines and training engines) and three trends that are likely to expand the standard AI software development system (further specialized models, better toolchain integrations, and increasingly modular systems).

- [Async engine](./where-we-are-heading/async.md)
- [Training engine](./where-we-are-heading/training.md)
- [Trends](./where-we-are-heading/trends.md)

AI software development systems are evolving quickly. In order to avoid vendor lock-in, keep up as new components emerge, and customize your AI dev system to your specific needs, you need an approach that gives you freedom and flexibility into the future.

## How to be prepared

The companies at the frontier like [Google](https://blog.research.google/2023/05/large-sequence-models-for-software.html), [Meta](https://arxiv.org/abs/2402.09171), [Nvidia](https://research.nvidia.com/publication/2023-10_chipnemo-domain-adapted-llms-chip-design), [Airbnb](https://youtu.be/_kV7fUVGz9E?si=9YWu-UQGE6CuPeuM), and [Uber](https://youtu.be/zQ5e3B5I-U0?si=UNtJo3DDxhrZBoE5) have platform development teams that create their own AI software development systems, which includes buying components from vendors when it makes sense.

We are seeing many more organizations head down the same path. Similar to when DevOps was known as “web operations”, we are in the early days of creating and standardizing workflows and tools. As we converge on best practices, platform development teams are positioning themselves to establish AI software development systems as a key aspect of their initiatives to improve developer experience.

While there’s definitely some work required to set up a good system, you can expect its value to increase over time, so start early! The organizations that find the most success will create the right set of initial conditions:

1. [Establish a modular, architecture of participation](./how-to-be-prepared/architecture.md)
2. [Enable the right models for the job](./how-to-be-prepared/models.md)
3. [Measure and improve system metrics](./how-to-be-prepared/metrics.md)
4. [Standardize permissions and integrations](./how-to-be-prepared/integrations.md)
5. [Adopt open-source, local-first interfaces](./how-to-be-prepared/interfaces.md)

## Conclusion

When a new tool enters your workflow, it changes how you think. As software development is increasingly automated, we need to be able to shape AI software development systems, so that we can shape how we think. But AI is not going to magically do everything. When it works, developers will move toward higher levels of abstraction. When it doesn’t, we should be able to do something about it.

This is another wave like DevOps, analytics, supervised ML systems, etc. which is expanding the number of problems available to reliable automation. As a result, the principles that will lead to success will be the same as they have always been: successful teams will set a foundation, adopt best practices, look to iterate, build internal tools, and talk candidly with their team.

All in all, each of us will need to actively participate in the construction and maintenance of AI software development systems. This shouldn’t be a surprise; if you or your fellow developers use a code assistance tool every day, maybe even seeing suggestions on every keystroke, you know that each improvement has a huge effect on productivity; as much, if not more, than any other developer tool that you could spend time and resources on improving.

If we put our energy into crafting the right AI software development systems in the right way, developers will be amplified, instead of being automated. Perhaps one day all developers will do is sit around a table discussing where to point their AI software development system next. But, for now, we have a lot of work to do to head towards that!