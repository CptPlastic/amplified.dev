# Code Completion model
The "code completion" model component is used to support autocomplete suggestions and is also referred to as the "tab-autocomplete model". Tab-autocomplete models use models trained with special templates, such as FiM(Fill in the Middle), that specialize in code infilling, and typically use small models, on the order of 1-15B for low latency. Because developers need a suggestion within 500ms, you generally need to use a smaller model in order to meet the latency requirements. However, the quality of suggestions you get from models that are too small is bad. Thus, the tab-autocomplete model is optimized primarily with these two constraints in mind. Examples of models used for tab-autocomplete include Codex, CodeGemma(2,7B), CodeLlama(7,13B), DeepSeek Coder Base(1.3,6.7,33B), StarCoder2(3,7,15B), ReplitCode(3B), etc.